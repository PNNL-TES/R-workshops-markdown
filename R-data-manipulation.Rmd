---
title: "Data manipulation using tidyverse R"
author: "Ben Bond-Lamberty"
date: "`r Sys.Date()`"
output: slidy_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Introduction

## The plan

A short workshop covering reproducibility and data management; data filtering, reshaping, and joining; and summarizing.

* Reproducible research and data management (~15 minutes)
* Filtering and cleaning data
* Reshaping data (~30 minutes; the `gapminder` dataset)
* Joining datasets (~30 minutes)
* Summarizing and manipulating data (~60 minutes; the `babynames` dataset)

## Requirements

This workshop assumes an intermediate knowledge of R.

If you want to do the hands-on exercises (encouraged!), make sure up-to-date versions of the following packages are installed:

* `dplyr`
* `tidyr`
* `gapminder`
* `babynames`

Note the first two constitute a [particular and popular dialect of R](http://tidyverse.org), but the principles we'll go over are broadly applicable. (I will point out base R equivalents as we go.)

# Reproducibility and data management

## Reproducibility...

We are in the era of collaborative 'big data', but even if you work by yourself with 'little data' you have to have some skills to deal with those data.

**Most fundamentally, your results have to be reproducible.**

>Your most important collaborator is your future self. It’s important to make a workflow that you can use time and time again, and even pass on to others in such a way that you don’t have to be there to walk them through it. [Source](http://berkeleysciencereview.com/reproducible-collaborative-data-science/)

## ...is the future

Even if you don't buy it, **prepare yourself for the future**. Funders, journals, governments, colleagues are all pushing for more reproducibility and openness. It's a slow but steady ratchet.

NSF, DOE, Wellcome, Gates, etc. are increasingly requiring data management plans; data deposition; publication in open-access journals.

Reproducibility generally means *scripts* tied to *open source software* with effective *data management* and *archiving*.

## You can't reproduce

...what you've lost. What if you need access to a file as it existed 1, 10, or 100, or 1000 days ago?

<div class='left' style='float:left;width:48%'>
- Incremental backups (minimum)
- Don't depend on yourself! Has to be _automatic_.
- Version control. A *repository* holds files and tracks changes: what, by whom, why
</div>
<div class='right' style='float:right;width:48%'>
<img src="data-manipulation-images/tardis.jpg" width="400" />
</div>

## Version control

**Git** (and website **GitHub**) are the most popular version control tools for use with R, and many other languages:

<div class='left' style='float:left;width:48%'>
- Version control
- Sharing code with collaborators in a *repository*
- Issue tracking
- Public or private
</div>
<div class='right' style='float:right;width:48%'>
<img src="data-manipulation-images/git_2x.png" width="300" />
</div>

## Data management during analysis

Version control and scripts address two of the biggest problems with managing code and data

* Tracking *changes over time*
* Understanding/reproducing *analytical steps*.

**Ideally, _every_ step in your analysis is programmatic**. This means it is performed by a script, so it can be understood and reproduced in the future.

## Reproducibility is a process

*Don't let the perfect be the enemy of the good.* Upgrade and improve your workflow and skills over time.

>Organizing analyses so that they are reproducible is not easy. It requires diligence and a considerable investment of time: to learn new computational tools, and to organize and document analyses as you go.

>But partially reproducible is better than not at all reproducible. Just try to make your next paper or project better organized than the last.

A great and practical guide: http://kbroman.org/steps2rr/

## Reproducible research example

A typical project/paper directory for me, slightly idealized:
```
1-download.R
2-prep_data.R
3-analyze_data.R
4-manuscript_report.Rmd
logs/
output/
rawdata/
```

This directory contains *scripts* that are backed up both *locally* and *remotely*. It is under *version control*, so it's easy to track changes over time.

There's also [targets](https://docs.ropensci.org/targets/), but that's a topic for another day.

# The end

## Thank you!

**Feedback welcome.**

* <a href="mailto:bondlamberty@pnnl">bondlamberty@pnnl.gov</a>
* [@BenBondLamberty](https://twitter.com/BenBondLamberty)
* https://github.com/bpbond/R-workshops/issues

The _slides_ for this presentation are available here: https://rpubs.com/bpbond/874167

The _repository_ with the R code that generated the slides is here: https://github.com/bpbond/R-workshops/
